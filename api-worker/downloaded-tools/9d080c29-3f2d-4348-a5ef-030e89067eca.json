{
  "name": "@egen-guru/mcp-ollama",
  "description": "@egen-guru/mcp-ollama MCP Server",
  "url": "@egen-guru/mcp-ollama",
  "protocol_version": "MCP/1.0",
  "capabilities": [
    {
      "name": "ollama_list",
      "type": "tool",
      "description": "Liste les modèles Ollama installés"
    },
    {
      "name": "query",
      "type": "tool",
      "description": "Génère une complétion via Ollama avec un prompt texte. Paramètres : prompt (string), model (optionnel, string, parmi : []). Le modèle par défaut est : deepseek-r1:latest. Si Ollama est occupé, la requête sera rejetée."
    },
    {
      "name": "chat",
      "type": "tool",
      "description": "Démarre une conversation avec Ollama (API /api/chat). Paramètres : messages (array de max 10 messages {role, content}), model (optionnel, string, parmi : []). Le modèle par défaut est : deepseek-r1:latest. Si Ollama est occupé, la requête sera rejetée."
    }
  ],
  "installation": {
    "command": "npx",
    "args": [
      "-y",
      "@egen-guru/mcp-ollama"
    ],
    "env": {}
  },
  "_id": "9d080c29-3f2d-4348-a5ef-030e89067eca",
  "_registeredAt": "2025-05-06T10:20:10.379Z",
  "_updatedAt": "2025-05-06T10:20:10.379Z",
  "_status": "unknown",
  "_lastChecked": null,
  "_kvId": "9d080c29-3f2d-4348-a5ef-030e89067eca"
}